{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f52fc4-3d19-415c-aece-ba45ef8397aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e580ec5-55b5-4665-9bc9-1b91e0c5c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love this product!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>6/15/2023 9:23:14 AM</td>\n",
       "      <td>@user123</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The service was terrible.\"</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yelp Reviews</td>\n",
       "      <td>6/15/2023 11:45:32 AM</td>\n",
       "      <td>user456</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"This movie is amazing!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>IMDb</td>\n",
       "      <td>6/15/2023 2:10:22 PM</td>\n",
       "      <td>moviefan789</td>\n",
       "      <td>London</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I'm so disappointed with their customer suppo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Online Forum</td>\n",
       "      <td>6/15/2023 5:35:11 PM</td>\n",
       "      <td>forumuser1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Just had the best meal of my life!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>6/16/2023 8:50:59 AM</td>\n",
       "      <td>foodie22</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  \\\n",
       "0                             \"I love this product!\"   Positive   \n",
       "1                        \"The service was terrible.\"   Negative   \n",
       "2                           \"This movie is amazing!\"   Positive   \n",
       "3  \"I'm so disappointed with their customer suppo...   Negative   \n",
       "4               \"Just had the best meal of my life!\"   Positive   \n",
       "\n",
       "          Source              Date/Time       User ID      Location  \\\n",
       "0        Twitter   6/15/2023 9:23:14 AM      @user123      New York   \n",
       "1   Yelp Reviews  6/15/2023 11:45:32 AM       user456   Los Angeles   \n",
       "2           IMDb   6/15/2023 2:10:22 PM   moviefan789        London   \n",
       "3   Online Forum   6/15/2023 5:35:11 PM    forumuser1       Toronto   \n",
       "4    TripAdvisor   6/16/2023 8:50:59 AM      foodie22         Paris   \n",
       "\n",
       "   Confidence Score  \n",
       "0              0.85  \n",
       "1              0.65  \n",
       "2              0.92  \n",
       "3              0.78  \n",
       "4              0.88  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/sentiment-analysis-1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efe631a-ad34-4847-a061-79461af45d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8cacc6-1c0e-4bda-9631-b96b1c217bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d24e1fc0-cc69-4449-a710-3bff145213e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I love this product!\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4df7603-bfb3-44b8-a756-152ea2ed91d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"i love this product!\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # converting into lower case\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13aaeb93-ab9b-4e8a-91d7-4b8b1db840d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love this product'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing punctuation\n",
    "text.translate(str.maketrans(\"\",\"\",string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff5244d3-c426-45a1-9431-62da80999fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am from bihar\n"
     ]
    }
   ],
   "source": [
    "# REMOVING WHITE-SPACES\n",
    "text1=' I am from bihar '\n",
    "clean_text= text1.strip()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a7989a-59c9-45de-9671-f9f8be5d97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iamfrombihar\n"
     ]
    }
   ],
   "source": [
    "# Remove all whitespaces\n",
    "text2=' I am from     Bihar '\n",
    "clean_text= text1.replace(\" \",\"\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374acd56-a5b9-4837-8bf8-b9376f4929d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ac328b-2cca-49bc-a4ea-9f37795126d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2=re.sub(' +',' ',text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37d7379-477f-4a10-875d-df3b500dc790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am from bihar \n"
     ]
    }
   ],
   "source": [
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8110318a-061d-4e38-ac27-b94927691b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing digits and special characters\n",
    "re.sub(r'[a-zA-Z\\s]','','Chandrayan-3 successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6213acc2-02f7-4e00-91f1-defe1af7887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"I', 'love', 'this', 'product!\"']\n"
     ]
    }
   ],
   "source": [
    "text3 = text.split()\n",
    "print(text3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9910c6c-94a9-4a4a-84ea-9df8f9785f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hiihe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7233f0-f6b8-4577-bf03-bca3d2ee126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'I', 'love', 'this', 'product', '!', \"''\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text3 = word_tokenize(text)\n",
    "print(text3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50c4c5c1-e3ad-4d6e-a5a6-0840f19fd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a31d2658-728a-4fa6-9cc0-c35c0bd72ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and', 'yourself', \"you've\", \"aren't\", 'there', 'aren', 'until', 'i', \"wasn't\", 'during', 'now', \"didn't\", 'below', \"we've\", \"wouldn't\", \"needn't\", 'this', \"i've\", 'do', \"doesn't\", 'weren', \"i'll\", 'over', 'just', 'she', 'wouldn', 'how', 'will', 'between', 'mightn', \"they'd\", 'won', \"you'd\", 'hers', 'needn', 'didn', 'off', 'your', 'when', 'don', \"hasn't\", 'doesn', 'because', 'shouldn', 'only', 'ain', 'y', 'but', 'them', 'ours', \"it'll\", 'theirs', \"haven't\", \"won't\", 'most', 'by', 'about', 'some', 'once', \"couldn't\", \"we'll\", 'again', 'after', \"she'd\", 'been', \"that'll\", 'have', 'are', 'on', 've', \"she's\", 'doing', 'own', 'shan', 'yours', \"isn't\", 'same', 'isn', 'herself', 'couldn', 'is', \"hadn't\", \"he'd\", 'were', 'against', 'yourselves', \"mustn't\", 'myself', 'before', 'his', 'we', 'has', 'nor', 'of', \"it'd\", 'should', \"i'm\", \"they've\", 'ma', 'haven', 'was', \"shouldn't\", \"he'll\", 'hadn', 'ourselves', 'they', 'where', 'to', 'my', 'these', 'too', 'very', 'wasn', 'a', 'can', \"they'll\", 'then', 'themselves', 're', 'not', \"shan't\", 'its', 'the', 'while', 'few', 'll', 'he', 'their', 'at', 'each', 'him', 'you', \"i'd\", \"they're\", \"you're\", 'm', 'through', 'all', 'into', 't', 'which', 'down', 'whom', 'had', 'from', 'both', \"he's\", 'itself', 'with', 'more', 'under', \"we're\", 'no', 'those', \"mightn't\", \"should've\", 'it', 'being', \"you'll\", 'what', 'did', 's', 'such', 'd', 'or', 'me', \"weren't\", 'that', 'be', 'further', 'here', 'hasn', 'in', 'mustn', 'as', \"she'll\", \"we'd\", \"it's\", 'does', \"don't\", 'why', 'other', 'than', 'any', 'for', 'himself', 'up', 'who', 'her', 'o', 'an', 'our', 'am', 'if', 'above', 'having', 'out', 'so'}\n"
     ]
    }
   ],
   "source": [
    "print(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ff31a9-4121-4617-91cb-f993aff08dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 68, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1=[5,5,68,0]\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "889b2bc8-d42f-490d-806d-dfb0d4a976a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 5, 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1= {5,2,1,10}\n",
    "set1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "403d4787-649d-4393-add2-955bb8d397cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today', 'weather', 'is', 'a', 'cloudy']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=[]\n",
    "text='Today weather is a cloudy'\n",
    "list1=nltk.word_tokenize(text)\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bceb6f8e-a59e-431f-96b1-7242ff2d27cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today\n",
      "weather\n",
      "cloudy\n"
     ]
    }
   ],
   "source": [
    "for i in list1:\n",
    "    if i not in stopwords.words('english'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67f15acd-7add-48b1-b971-4842a94cf5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today', 'weather', 'cloudy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1=[i for i in list1 if i not in stopwords.words('english')]\n",
    "word1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0400f331-645e-46fd-b98a-db51ffceac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today  weather  cloudy\n"
     ]
    }
   ],
   "source": [
    "print('  '.join(word1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a36c85eb-c4a3-473e-a4fa-387eff9edf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower casing the text\n",
    "def lower_case(txt):\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88bd4484-a1d3-4edb-b1ed-f3b2573c0500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation \n",
    "def remove_punc(txt):\n",
    "    return txt.translate(str.maketrans(\"\",\"\",string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47c86a4d-67c7-47c6-87c1-2b168d9fd318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove digits and special characters\n",
    "def remove_dig_char(txt):\n",
    "    return re.sub(r'[^a-zA-Z\\s]','','Chandrayan-3 successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84e48675-6af4-4060-a9f4-473add8c3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespaces\n",
    "def remove_spaces(txt):\n",
    "    return re.sub(' +',' ',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "314dd024-599a-4f7d-88d3-e4f1719ae9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "def remove_stopwords(txt):\n",
    "    list1=nltk.word_tokenize(txt)\n",
    "    words=[i for i in list1 if i not in stopwords.words('english')]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "682805b4-3e7c-4d13-ab82-e005aebbbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning function \n",
    "def clean(txt):\n",
    "    txt=lower_case(txt)\n",
    "    txt=remove_punc(txt)\n",
    "    txt=remove_dig_char(txt)\n",
    "    txt=remove_spaces(txt)\n",
    "    txt=remove_stopwords(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e37263f5-f53d-4000-ac96-c1bffe6c30cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hiihe\\AppData\\Local\\Temp\\ipykernel_10836\\2577722606.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_txt']=df['Text'].apply(clean)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confidence Score</th>\n",
       "      <th>cleaned_txt</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love this product!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>6/15/2023 9:23:14 AM</td>\n",
       "      <td>@user123</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The service was terrible.\"</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yelp Reviews</td>\n",
       "      <td>6/15/2023 11:45:32 AM</td>\n",
       "      <td>user456</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"This movie is amazing!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>IMDb</td>\n",
       "      <td>6/15/2023 2:10:22 PM</td>\n",
       "      <td>moviefan789</td>\n",
       "      <td>London</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I'm so disappointed with their customer suppo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Online Forum</td>\n",
       "      <td>6/15/2023 5:35:11 PM</td>\n",
       "      <td>forumuser1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.78</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Just had the best meal of my life!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>6/16/2023 8:50:59 AM</td>\n",
       "      <td>foodie22</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  \\\n",
       "0                             \"I love this product!\"   Positive   \n",
       "1                        \"The service was terrible.\"   Negative   \n",
       "2                           \"This movie is amazing!\"   Positive   \n",
       "3  \"I'm so disappointed with their customer suppo...   Negative   \n",
       "4               \"Just had the best meal of my life!\"   Positive   \n",
       "\n",
       "          Source              Date/Time       User ID      Location  \\\n",
       "0        Twitter   6/15/2023 9:23:14 AM      @user123      New York   \n",
       "1   Yelp Reviews  6/15/2023 11:45:32 AM       user456   Los Angeles   \n",
       "2           IMDb   6/15/2023 2:10:22 PM   moviefan789        London   \n",
       "3   Online Forum   6/15/2023 5:35:11 PM    forumuser1       Toronto   \n",
       "4    TripAdvisor   6/16/2023 8:50:59 AM      foodie22         Paris   \n",
       "\n",
       "   Confidence Score            cleaned_txt           cleaned_text  \n",
       "0              0.85  Chandrayan successful  Chandrayan successful  \n",
       "1              0.65  Chandrayan successful  Chandrayan successful  \n",
       "2              0.92  Chandrayan successful  Chandrayan successful  \n",
       "3              0.78  Chandrayan successful  Chandrayan successful  \n",
       "4              0.88  Chandrayan successful  Chandrayan successful  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_txt']=df['Text'].apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1e4614f-394d-48b1-b31d-9c1725254fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 96 entries, 0 to 95\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Text              96 non-null     object \n",
      " 1   Sentiment         96 non-null     object \n",
      " 2   Source            96 non-null     object \n",
      " 3   Date/Time         96 non-null     object \n",
      " 4   User ID           96 non-null     object \n",
      " 5   Location          96 non-null     object \n",
      " 6   Confidence Score  96 non-null     float64\n",
      " 7   cleaned_txt       96 non-null     object \n",
      " 8   cleaned_text      96 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 7.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d05c5fab-ceb1-41fa-940e-826c1a8c7cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text                0\n",
       "Sentiment           0\n",
       "Source              0\n",
       "Date/Time           0\n",
       "User ID             0\n",
       "Location            0\n",
       "Confidence Score    0\n",
       "cleaned_txt         0\n",
       "cleaned_text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d8d5e61-0b43-4d9c-97b9-02ecc353aedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confidence Score</th>\n",
       "      <th>cleaned_txt</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love this product!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>6/15/2023 9:23:14 AM</td>\n",
       "      <td>@user123</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The service was terrible.\"</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yelp Reviews</td>\n",
       "      <td>6/15/2023 11:45:32 AM</td>\n",
       "      <td>user456</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"This movie is amazing!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>IMDb</td>\n",
       "      <td>6/15/2023 2:10:22 PM</td>\n",
       "      <td>moviefan789</td>\n",
       "      <td>London</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I'm so disappointed with their customer suppo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Online Forum</td>\n",
       "      <td>6/15/2023 5:35:11 PM</td>\n",
       "      <td>forumuser1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.78</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Just had the best meal of my life!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>6/16/2023 8:50:59 AM</td>\n",
       "      <td>foodie22</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  \\\n",
       "0                             \"I love this product!\"   Positive   \n",
       "1                        \"The service was terrible.\"   Negative   \n",
       "2                           \"This movie is amazing!\"   Positive   \n",
       "3  \"I'm so disappointed with their customer suppo...   Negative   \n",
       "4               \"Just had the best meal of my life!\"   Positive   \n",
       "\n",
       "          Source              Date/Time       User ID      Location  \\\n",
       "0        Twitter   6/15/2023 9:23:14 AM      @user123      New York   \n",
       "1   Yelp Reviews  6/15/2023 11:45:32 AM       user456   Los Angeles   \n",
       "2           IMDb   6/15/2023 2:10:22 PM   moviefan789        London   \n",
       "3   Online Forum   6/15/2023 5:35:11 PM    forumuser1       Toronto   \n",
       "4    TripAdvisor   6/16/2023 8:50:59 AM      foodie22         Paris   \n",
       "\n",
       "   Confidence Score            cleaned_txt           cleaned_text  \n",
       "0              0.85  Chandrayan successful  Chandrayan successful  \n",
       "1              0.65  Chandrayan successful  Chandrayan successful  \n",
       "2              0.92  Chandrayan successful  Chandrayan successful  \n",
       "3              0.78  Chandrayan successful  Chandrayan successful  \n",
       "4              0.88  Chandrayan successful  Chandrayan successful  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text']=df['Text'].apply(clean)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "666fb96b-1025-4427-8fc7-e47b56d338b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text', 'Sentiment', 'Source', 'Date/Time', 'User ID', 'Location',\n",
      "       'Confidence Score', 'cleaned_txt', 'cleaned_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5e3d06d-10eb-4612-9555-b0d51afba953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love this product!\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The service was terrible.\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"This movie is amazing!\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I'm so disappointed with their customer suppo...</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Just had the best meal of my life!\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"The quality of this product is subpar.\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I can't stop listening to this song. It's inc...</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Their website is so user-friendly. Love it!\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"I loved the movie! It was fantastic!\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"The customer service was terrible.\"</td>\n",
       "      <td>Chandrayan successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text           cleaned_text\n",
       "0                             \"I love this product!\"  Chandrayan successful\n",
       "1                        \"The service was terrible.\"  Chandrayan successful\n",
       "2                           \"This movie is amazing!\"  Chandrayan successful\n",
       "3  \"I'm so disappointed with their customer suppo...  Chandrayan successful\n",
       "4               \"Just had the best meal of my life!\"  Chandrayan successful\n",
       "5           \"The quality of this product is subpar.\"  Chandrayan successful\n",
       "6  \"I can't stop listening to this song. It's inc...  Chandrayan successful\n",
       "7      \"Their website is so user-friendly. Love it!\"  Chandrayan successful\n",
       "8             \"I loved the movie! It was fantastic!\"  Chandrayan successful\n",
       "9               \"The customer service was terrible.\"  Chandrayan successful"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparision=df[['Text','cleaned_text']].head(10)\n",
    "comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5493fe-91e0-4c1e-97ff-2c8b8dbfcc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee5933-9b36-4c64-9702-cc4b131dd5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d432fc-ca05-4d50-8a0c-5eaf9c25cef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
